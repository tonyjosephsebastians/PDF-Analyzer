## PDF Document Analyzer - Technical Documentation

### Overview

The PDF Document Analyzer is a Streamlit application that allows users to upload PDF files, ask questions about the content, and receive answers generated by a language model. It uses a Retrieval-Augmented Generation (RAG) approach to provide relevant and informative responses.

### Technologies Used

*   Streamlit: For creating the web application.
*   Pandas: For loading and manipulating structured data if needed.
*   Langchain: To orchestrate the RAG pipeline.
*   Hugging Face Embeddings: For generating embeddings.
*   FAISS: For the vector database.
*   Google Gemini API: For the language model.
*   PyMuPDF: For extracting text from PDFs.

### Setup

1.  Install the required libraries:
    `pip install streamlit pandas sentence-transformers faiss-cpu langchain google-generativeai pymupdf`
2.  Obtain a Google Gemini API key and enter it in the sidebar of the application.
3.  Upload a PDF file using the file uploader.
4.  Ask questions about the document in the text input field.
5.  The application will display the answer generated by the language model.

### Code Structure

*   `app.py`: Contains the main application code, including the UI elements, data loading, chunking, embedding, retrieval, and response generation logic.
*   `run_app.bat`: A batch file that launches the Streamlit application.
*   `documentation.txt`: This file, providing technical documentation for the application.

### RAG Pipeline

1.  **Data Loading:** The application extracts text from the uploaded PDF using PyMuPDF.
2.  **Data Chunking:** The extracted text is split into smaller chunks using `CharacterTextSplitter`.
3.  **Embedding Generation:** Embeddings are generated for each chunk using `HuggingFaceEmbeddings`.
4.  **Vector Database:** The chunks and their embeddings are stored in a FAISS vector database.
5.  **Retrieval:** When a question is asked, the application generates an embedding for the question and searches the vector database for the most similar chunks.
6.  **Response Generation:** The question and the retrieved chunks are passed to the Google Gemini API to generate an answer.

### Batch File

The `run_app.bat` file contains the following commands:

*   `@echo off`: Disables command echoing.
*   `echo Starting Streamlit app...`: Displays a message indicating that the Streamlit app is starting.
*   `streamlit run app.py`: Runs the Streamlit application.
*   `pause`: Pauses the command prompt window after the application is closed, allowing the user to see any error messages.

### Customization

*   The chunk size and overlap can be adjusted in the `app.py` file to optimize the retrieval performance.
*   The language model can be changed by modifying the `model_name` parameter in the `ChatGoogleGenerativeAI` class.
*   The UI can be further customized using Streamlit's API.

### Troubleshooting

*   If the application fails to start, ensure that all the required libraries are installed and that the Google Gemini API key is valid.
*   If the application returns incorrect answers, try adjusting the chunking parameters or modifying the prompt to the language model.
